
services:
  postgres:
    env_file:
      - .env.local.compose
    image: postgres:15-alpine
    container_name: sacred_qa_postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ai_qa_platform}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password_123}
      POSTGRES_HOST_AUTH_METHOD: md5
      # Additional settings for better initialization
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    command: 
      - "postgres"
      - "-c"
      - "password_encryption=md5"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Optional: Add init scripts if needed
      # - ./docker/postgres/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-ai_qa_platform}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - sacred_qa_network

  valkey:
    image: valkey/valkey:7-alpine
    container_name: sacred_qa_valkey
    restart: unless-stopped
    ports:
      - "${VALKEY_PORT:-6379}:6379"
    volumes:
      - valkey_data:/data
    command: ["valkey-server", "--loglevel", "debug", "--save", ""]
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 30s
    networks:
      - sacred_qa_network

  ai-inference:
    build: 
      context: ./inference
      dockerfile: Dockerfile
    image: sacred-qa/ai-inference:latest
    container_name: sacred_qa_ai_inference
    restart: unless-stopped
    command: ["python", "server.py"]
    ports:
      - "${AI_SERVICE_PORT:-8001}:8001"
    environment:
      - DEVICE=${AI_DEVICE:-auto}
      - MODEL_PATH=${MODEL_PATH:-/models}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      # Mount model directory if using local models
      - ./models:/models:ro
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - sacred_qa_network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file:
      - .env.local.compose
    image: sacred-qa/backend:latest
    container_name: sacred_qa_backend
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    environment:
      DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-secure_password_123}@postgres:5432/${POSTGRES_DB:-ai_qa_platform}
      VALKEY_URL: redis://valkey:6379/0
      # Database configuration
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${POSTGRES_DB:-ai_qa_platform}
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password_123}
      
      # Redis/Valkey configuration
      VALKEY_HOST: valkey
      VALKEY_PORT: 6379
      
      # AI Service configuration
      AI_SERVICE_HOST: ai-inference
      AI_SERVICE_PORT: 8001
      INFERENCE_URL: http://ai-inference:8001
      
      # Application settings
      NODE_ENV: ${NODE_ENV:-development}
      JWT_SECRET: ${JWT_SECRET:-your-secret-key-change-in-production}
      API_PREFIX: ${API_PREFIX:-/api/v1}
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
      DEBUG: "true"
      LOG_LEVEL: DEBUG
    volumes:
      # Mount source code for development (with hot reload)
      - ./backend:/app
      - backend_node_modules:/app/node_modules
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
      ai-inference:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - sacred_qa_network

  frontend:
    build:
      context: ./apps
      dockerfile: Dockerfile
    image: sacred-qa/frontend:latest
    container_name: sacred_qa_frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    environment:
      NEXT_PUBLIC_API_URL: ${API_URL:-http://localhost:8000/api/v1}
      NEXT_PUBLIC_WS_URL: ${WS_URL:-ws://localhost:8000}
    volumes:
      # Development mode with hot reload
      - frontend_node_modules:/app/node_modules
      - frontend_next:/app/.next
    depends_on:
      backend:
        condition: service_started
    networks:
      - sacred_qa_network

  # nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: sacred_qa_nginx
    restart: unless-stopped
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/conf.d:/etc/nginx/conf.d:ro
      # SSL certificates if needed
      - ./docker/nginx/certs:/etc/nginx/certs:ro
    depends_on:
      frontend:
        condition: service_started
      backend:
        condition: service_started
    networks:
      - sacred_qa_network

volumes:
  postgres_data:
    name: sacred_qa_postgres_data
  valkey_data:
    name: sacred_qa_valkey_data
  backend_node_modules:
  frontend_node_modules:
  frontend_next:

networks:
  sacred_qa_network:
    name: sacred_qa_network
    driver: bridge
     
